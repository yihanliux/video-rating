from flask import Flask, render_template, request, jsonify
import os
import cv2
import mediapipe as mp
import matplotlib.pyplot as plt
from tqdm import tqdm
import numpy as np
import ruptures as rpt
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from scipy.signal import savgol_filter
import statsmodels.api as sm
from PIL import Image

# åˆå§‹åŒ–MediaPipe
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils 
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=2,
    smooth_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
# å…³é”®ç‚¹ç´¢å¼•
NOSE, LEFT_EAR, RIGHT_EAR, LEFT_MOUTH, RIGHT_MOUTH = 0, 7, 8, 9, 10
LEFT_SHOULDER, RIGHT_SHOULDER = 11, 12
LEFT_HIP, RIGHT_HIP = 23, 24
LEFT_KNEE, RIGHT_KNEE = 25, 26
LEFT_ANKLE, RIGHT_ANKLE = 27, 28

# å¤´éƒ¨å’Œè„šéƒ¨çš„ Mediapipe å…³é”®ç‚¹ç´¢å¼•
head_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # å¤´éƒ¨ 10 ä¸ªç‚¹
foot_indices = [27, 28, 29, 30, 31, 32]  # è„šéƒ¨ 6 ä¸ªç‚¹

def euclidean_dist(x1, y1, x2, y2):
    """è®¡ç®—ä¸¤ä¸ªç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)

def max_head_to_foot_distance(cx_list, cy_list):
    max_distance = 0
    
    # éå†æ‰€æœ‰å¤´éƒ¨å’Œè„šéƒ¨ç‚¹ï¼Œè®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
    for h in head_indices:
        for f in foot_indices:
            x1, y1 = cx_list[h], cy_list[h]
            x2, y2 = cx_list[f], cy_list[f]
            
            # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
            distance = euclidean_dist(x1, y1, x2, y2)
            
            # è®°å½•æœ€å¤§è·ç¦»
            if distance > max_distance:
                max_distance = distance
    
    return max_distance

def calculate_body_height(cx_list, cy_list):
    """è®¡ç®—äººä½“çš„å®Œæ•´é«˜åº¦ï¼ŒåŒ…æ‹¬å¤´é¡¶å’Œè„šåº•ï¼Œå¹¶è¿”å› body_height"""

    # è®¡ç®—è‚©è†€ä¸­ç‚¹
    shoulder_mid_x = (cx_list[LEFT_SHOULDER] + cx_list[RIGHT_SHOULDER]) / 2
    shoulder_mid_y = (cy_list[LEFT_SHOULDER] + cy_list[RIGHT_SHOULDER]) / 2

    # è®¡ç®—é¼»å­åˆ°è‚©è†€ä¸­ç‚¹çš„è·ç¦»
    head_to_shoulder = euclidean_dist(cx_list[NOSE], cy_list[NOSE], shoulder_mid_x, shoulder_mid_y)

    # è®¡ç®—å·¦ä¾§å’Œå³ä¾§èº«é«˜ï¼ˆä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰
    def compute_side_height(shoulder, hip, knee, ankle):
        parts = [
            (cx_list[shoulder], cy_list[shoulder], cx_list[hip], cy_list[hip]),  # è‚©åˆ°é«‹
            (cx_list[hip], cy_list[hip], cx_list[knee], cy_list[knee]),          # é«‹åˆ°è†
            (cx_list[knee], cy_list[knee], cx_list[ankle], cy_list[ankle])       # è†åˆ°è¸
        ]
        return sum(euclidean_dist(x1, y1, x2, y2) for x1, y1, x2, y2 in parts)

    left_height = compute_side_height(LEFT_SHOULDER, LEFT_HIP, LEFT_KNEE, LEFT_ANKLE)
    right_height = compute_side_height(RIGHT_SHOULDER, RIGHT_HIP, RIGHT_KNEE, RIGHT_ANKLE)

    # è®¡ç®—äººä½“æ€»é«˜åº¦
    body_height = max(left_height, right_height)
    body_height += head_to_shoulder  # åŠ ä¸Šé¼»å­åˆ°è‚©è†€çš„é«˜åº¦
    body_height += 1.7 * head_to_shoulder  # åŠ ä¸Šå¤´é¡¶åˆ°é¼»å­çš„é«˜åº¦
    body_height += 0.05 * body_height # åŠ ä¸Šè„šçš„é«˜åº¦

    max_distance = max_head_to_foot_distance(cx_list, cy_list)

    return max(body_height, max_distance)

def calculate_head_y(cy_list, body_height):
    """è®¡ç®—å¤´éƒ¨çš„å½’ä¸€åŒ–é«˜åº¦ï¼ˆç›¸å¯¹äºåœ°é¢é«˜åº¦ï¼‰ï¼Œå¤„ç† None å€¼"""
    
    valid_y_values = [y for y in cy_list if y is not None]
    ground_y = max(valid_y_values)

    head_y = (ground_y - cy_list[NOSE]) / body_height

    return head_y

def analyze_orientation(cx_list, cy_list):
    # è®¡ç®—é¼»å­-å·¦è€³ã€é¼»å­-å³è€³çš„è§’åº¦
    dx_left = cy_list[NOSE] - cy_list[LEFT_EAR]
    dy_left = cx_list[NOSE] - cx_list[LEFT_EAR]

    dx_right = cy_list[NOSE] - cy_list[RIGHT_EAR]
    dy_right = cx_list[NOSE] - cx_list[RIGHT_EAR]

    # è®¡ç®—å·¦å³è€³ç›¸å¯¹é¼»å­çš„è§’åº¦ï¼ˆè½¬æ¢ä¸ºè§’åº¦åˆ¶ï¼‰
    angle_left = abs(np.degrees(np.arctan2(dy_left, dx_left)))
    angle_right = abs(np.degrees(np.arctan2(dy_right, dx_right)))

    # è®¡ç®—å¹³å‡è§’åº¦
    avg_angle = (angle_left + angle_right) / 2

    dy_mouth = (cy_list[LEFT_MOUTH] + cy_list[RIGHT_MOUTH])/2

    # æ ¹æ®è§’åº¦åˆ†ç±»å§¿æ€
    if 40 <= avg_angle <= 100:
        if cy_list[NOSE] > dy_mouth:
            return "down"
        else:
            return "neutral"
    elif 0 <= avg_angle <= 40:
        return "down" 
    elif 100 <= avg_angle <= 180:
        return "up"
    else:
        return "unknown"

def process_pose(image):
    """å¤„ç†äººä½“å§¿æ€ï¼Œè¿”å›å…³é”®ç‚¹åæ ‡ï¼Œå¦‚æœæ•°æ®ç¼ºå¤±åˆ™ç›´æ¥è¿”å› 'Insufficient data'"""

    # é¢œè‰²è½¬æ¢ (BGR -> RGB)
    img_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # è¿›è¡Œå§¿æ€æ£€æµ‹
    results = pose.process(img_RGB)
    
    # ç¡®ä¿ `pose_landmarks` å­˜åœ¨
    if not results.pose_landmarks:
        return "Insufficient data"

    # è·å–å›¾åƒå®½é«˜
    h, w = image.shape[:2]

    # æå–æ‰€æœ‰ 33 ä¸ªå…³é”®ç‚¹çš„åƒç´ åæ ‡
    cx_list = [int(lm.x * w) for lm in results.pose_landmarks.landmark]
    cy_list = [int(lm.y * h) for lm in results.pose_landmarks.landmark]

    # éœ€è¦çš„å…³é”®ç‚¹ç´¢å¼•
    required_points = [NOSE, LEFT_EAR, RIGHT_EAR, LEFT_SHOULDER, RIGHT_SHOULDER,
                       LEFT_HIP, RIGHT_HIP, LEFT_KNEE, RIGHT_KNEE, LEFT_ANKLE, RIGHT_ANKLE]

    # å…³é”®ç‚¹å®Œæ•´æ€§æ£€æŸ¥
    if any(cx_list[p] is None or cy_list[p] is None for p in required_points):
        return "Insufficient data"

    return cx_list, cy_list

def process_frame(image):
    """å¤„ç†å•å¸§å›¾åƒï¼Œå¹¶è¿”å› JSON è®°å½•"""

    if image is None:
        return None
    
    frame_data = {
        "body_height": None,
        "orientation": None,
        "head_y": None
    }

    pose_data = process_pose(image)
    if pose_data != "Insufficient data":
        cx_list, cy_list = pose_data

        body_height = calculate_body_height(cx_list, cy_list)
        frame_data.update({"body_height": body_height})

        orientation = analyze_orientation(cx_list, cy_list)
        frame_data.update({"orientation": orientation})

        head_y = calculate_head_y(cy_list, body_height)
        frame_data.update({"head_y": head_y})
    
    return frame_data


def generate_video(input_video):
    """è¯»å–è§†é¢‘ï¼Œæ¯ 2 å¸§è¯»å– 1 å¸§ï¼Œå¹¶è¿”å›æ‰€æœ‰å¸§çš„æ•°æ®åˆ—è¡¨"""

    try:
        cap = cv2.VideoCapture(input_video)
        if not cap.isOpened():
            raise ValueError("é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼")
    except Exception as e:
        print(f"è§†é¢‘è¯»å–å¤±è´¥: {e}")
        return None, None
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_data_list = []  # å­˜å‚¨å¸§æ•°æ®
    last_frame_data = None  # è®°å½•ä¸Šä¸€å¸§çš„æ•°æ®
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    with tqdm(total=total_frames) as pbar:
        frame_idx = 0
        while cap.isOpened():
            success, frame = cap.read()
            if not success or frame is None:
                break

            if frame_idx % 2 == 0:  # æ¯ 2 å¸§å¤„ç† 1 å¸§
                try:
                    frame_data = process_frame(frame)
                    last_frame_data = frame_data  # æ›´æ–°ä¸Šä¸€å¸§æ•°æ®
                except Exception as e:
                    print(f"å¤„ç†å¸§æ—¶å‡ºé”™: {e}")
                    frame_data = None
            else:
                frame_data = last_frame_data  # å¤åˆ¶ä¸Šä¸€å¸§çš„æ•°æ®

            frame_data_list.append(frame_data)
            frame_idx += 1
            pbar.update(1)

    cap.release()
    cv2.destroyAllWindows()
    
    return frame_data_list, fps

def extract_data_from_frame_list(frame_data_list):
    """ä» frame_data_list ä¸­æå– 4 ä¸ªç‹¬ç«‹çš„æ•°ç»„"""
    body_height_list = []
    orientation_list = []
    head_y_list = []

    for frame_data in frame_data_list:
        if frame_data is None:
            # å¦‚æœ frame_data æ˜¯ Noneï¼Œåˆ™æ·»åŠ  None å ä½ç¬¦
            body_height_list.append(None)
            orientation_list.append(None)
            head_y_list.append(None)
        else:
            # ä»æ¯ä¸€ä¸ª frame_data æå–å¯¹åº”æ•°æ®
            body_height_list.append(frame_data.get("body_height"))
            orientation_list.append(frame_data.get("orientation"))
            head_y_list.append(frame_data.get("head_y"))
    
    return body_height_list, orientation_list, head_y_list

def smooth_stable_data(orientation, window_size=10, consensus_ratio=0.8):
    """
    å¹³æ»‘æ•°æ®ï¼Œç§»é™¤å™ªéŸ³ï¼Œä½¿ `people_counts` å’Œ `orientation` æ›´ç¨³å®šã€‚
    
    è¯¥æ–¹æ³•ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—æœ€å¸¸è§å€¼ï¼Œå¹¶åœ¨æ¯”ä¾‹è¾¾åˆ° `consensus_ratio` æ—¶æ›¿æ¢å½“å‰å€¼ï¼Œ
    ä»¥å‡å°‘å™ªå£°çš„å½±å“ï¼Œä½¿æ•°æ®æ›´å¹³æ»‘ã€‚
    
    å‚æ•°:
        people_counts (list[int]): æ¯ä¸€å¸§æ£€æµ‹åˆ°çš„äººæ•°æ•°æ®ã€‚
        orientation (list[str]): æ¯ä¸€å¸§çš„é¢éƒ¨æœå‘ä¿¡æ¯ã€‚
        motion_states (list[str]): æ¯ä¸€å¸§çš„è¿åŠ¨çŠ¶æ€ ('static' æˆ– 'dynamic')ã€‚
        window_size (int): æ»‘åŠ¨çª—å£çš„å¤§å°ï¼Œå†³å®šå¹³æ»‘æ—¶è€ƒè™‘çš„å¸§æ•°ï¼ˆé»˜è®¤ 10ï¼‰ã€‚
        consensus_ratio (float): è®¤å®šæœ€å¸¸è§å€¼çš„æ¯”ä¾‹ï¼Œè‹¥è¾¾åˆ°è¯¥æ¯”ä¾‹åˆ™é‡‡ç”¨æœ€å¸¸è§å€¼ï¼ˆé»˜è®¤ 0.8ï¼‰ã€‚

    è¿”å›:
        tuple: åŒ…å«å¹³æ»‘åçš„æ•°æ®ï¼š
            - filtered_people_counts (list[int]): å¹³æ»‘åçš„äººæ•°æ•°æ®ã€‚
            - filtered_orientation (list[str]): å¹³æ»‘åçš„é¢éƒ¨æœå‘æ•°æ®ã€‚
            - filtered_motion_states (list[str]): å¹³æ»‘åçš„è¿åŠ¨çŠ¶æ€æ•°æ®ã€‚
    """
    
    # å¤åˆ¶åŸå§‹æ•°æ®ï¼Œé¿å…ä¿®æ”¹è¾“å…¥åˆ—è¡¨
    filtered_orientation = orientation[:]

    # éå†æ‰€æœ‰å¸§æ•°æ®
    for i in range(len(orientation)):
        # å®šä¹‰æ»‘åŠ¨çª—å£çš„èŒƒå›´
        start, end = max(0, i - window_size), min(len(orientation), i + window_size)
        # è®¡ç®—æ»‘åŠ¨çª—å£å†…çš„æœ€å¸¸è§å€¼
        most_common_orientation = max(set(orientation[start:end]), key=orientation[start:end].count)
        # è®¡ç®—æœ€å¸¸è§å€¼çš„å æ¯”
        orientation_consensus = orientation[start:end].count(most_common_orientation) / (end - start)
        # å¦‚æœæœ€å¸¸è§å€¼çš„æ¯”ä¾‹è¶…è¿‡ `consensus_ratio`ï¼Œåˆ™é‡‡ç”¨å®ƒï¼Œå¦åˆ™ä¿æŒåŸå€¼
        filtered_orientation[i] = most_common_orientation if orientation_consensus >= consensus_ratio else orientation[i]

    return filtered_orientation

def first_orientation_segments(orientation, body_height, head_y, fps):

    orient_segments = []
    current_orient, start_frame = None, None

    # é¢„å¤„ç†ï¼Œå°† None å˜æˆ 'Invalid'
    orientation = ['Invalid' if orientation is None else orient for orient in orientation]

    for i in range(len(body_height)):
        if body_height[i] is None or head_y[i] is None:
            orientation[i] = "Invalid"  # ä¿®æ”¹ orientation

    # éå†æ¯ä¸€å¸§çš„å§¿æ€æ–¹å‘ï¼Œåˆ†å‰²ä¸åŒçš„ç‰‡æ®µ
    for i, orient in enumerate(orientation):
        if current_orient is None:
            current_orient, start_frame = orient, i
        elif orient != current_orient:
            end_frame = i - 1
            duration = end_frame - start_frame + 1
            orient_segments.append({
                "orient": current_orient,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "duration_sec": duration / fps,
                "duration_frames": duration
            })
            current_orient, start_frame = orient, i

    # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µ
    if current_orient is not None:
        end_frame = len(orientation) - 1
        duration = end_frame - start_frame + 1
        orient_segments.append({
            "orient": current_orient,
            "start_frame": start_frame,
            "end_frame": end_frame,
            "duration_sec": duration / fps,
            "duration_frames": duration
        })

    return orient_segments

def filter_invalid_orientation_segments(orient_segments, orientation, body_height, head_y, fps=30, min_duration_sec=3, max_duration_sec=90):
    
    min_duration_frames = fps * min_duration_sec
    max_duration_frames = fps * max_duration_sec
    total_frames = len(orientation)
    
    # è®¡ç®—å‰ 10% å’Œå 10% çš„å¸§èŒƒå›´
    first_10_percent = min(int(0.1 * total_frames), max_duration_sec)
    last_10_percent = max(int(0.9 * total_frames), total_frames - max_duration_frames)
    
    # æ‰¾å‡ºæ‰€æœ‰ "Invalid" ç‰‡æ®µ
    long_invalid_segments = []
    first_invalid_in_10_percent = None
    last_invalid_in_90_percent = None

    for segment in orient_segments:
        if segment["orient"] == "Invalid":
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ min_duration_frames
            if segment["duration_frames"] > min_duration_frames:
                long_invalid_segments.append(segment)

            # æ£€æŸ¥æ˜¯å¦åœ¨å‰10%
            if segment["end_frame"] < first_10_percent:
                first_invalid_in_10_percent = segment  # æŒç»­æ›´æ–°ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ª
            # æ£€æŸ¥æ˜¯å¦åœ¨å10%
            elif segment["start_frame"] >= last_10_percent and last_invalid_in_90_percent is None:
                last_invalid_in_90_percent = segment  # ä»…æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°±åœ

    # æ›´æ–° orientation_segments ä½¿å¾—å‰åç‰‡æ®µå˜ä¸º "Invalid"
    new_orient_segments = []
    invalid_mode = False  # è¿™ä¸ªæ ‡å¿—å†³å®šæ˜¯å¦å°†åç»­ç‰‡æ®µè®¾ä¸º "Invalid"

    for segment in orient_segments:
        if first_invalid_in_10_percent and segment["end_frame"] <= first_invalid_in_10_percent["end_frame"]:
            invalid_mode = True  # è§¦å‘ Invalid æ¨¡å¼

        if last_invalid_in_90_percent and segment["start_frame"] >= last_invalid_in_90_percent["start_frame"]:
            invalid_mode = True  # è§¦å‘ Invalid æ¨¡å¼
        
        if invalid_mode:
            # å°†å½“å‰ç‰‡æ®µå˜ä¸º Invalid
            new_segment = segment.copy()
            new_segment["orient"] = "Invalid"
            new_orient_segments.append(new_segment)
        else:
            new_orient_segments.append(segment)


    # 4ï¸âƒ£ åˆ é™¤è¶…è¿‡ 1 ç§’çš„ "Invalid" ç‰‡æ®µ
    frames_to_remove = set()
    for segment in orient_segments:
        if segment["orient"] == "Invalid":
            frames_to_remove.update(range(segment["start_frame"], segment["end_frame"] + 1))
    
    updated_orient_segments = []
    for segment in orient_segments:
        if segment["orient"] == "Invalid" :
            print(f"Deleted Invalid segment: Start {segment['start_frame']}, End {segment['end_frame']}, Duration {segment['duration_frames']} frames ({segment['duration_sec']} sec)")
        else:
            updated_orient_segments.append(segment)  # åªä¿ç•™æœªè¢«åˆ é™¤çš„ç‰‡æ®µ

    frames_to_keep = set(range(total_frames)) - frames_to_remove
    updated_orientation = [orientation[i] for i in frames_to_keep]
    updated_body_height = [body_height[i] for i in frames_to_keep]
    updated_head_y = [head_y[i] for i in frames_to_keep]
    
    if updated_orient_segments:
        new_segments = []
        prev_end_frame = 0
        
        for seg in updated_orient_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)
        
        updated_orient_segments = new_segments

    return updated_orient_segments, updated_orientation, updated_body_height, updated_head_y
    
def compute_adaptive_threshold(data, method="std", k=2):
    """
    è®¡ç®—æ•°æ®çš„è‡ªé€‚åº”é˜ˆå€¼ï¼Œç”¨äºæ£€æµ‹å¼‚å¸¸å€¼ã€‚

    è¯¥å‡½æ•°æ ¹æ®ä¸åŒçš„ç»Ÿè®¡æ–¹æ³•è®¡ç®—æ•°æ®çš„åŠ¨æ€é˜ˆå€¼ï¼š
    - method="std"  -> ä½¿ç”¨æ ‡å‡†å·®è®¡ç®—é˜ˆå€¼ï¼šthreshold = k * std
    - method="mad"  -> ä½¿ç”¨å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰è®¡ç®—é˜ˆå€¼
    - method="iqr"  -> ä½¿ç”¨ IQRï¼ˆå››åˆ†ä½è·ï¼‰è®¡ç®—é˜ˆå€¼

    å‚æ•°ï¼š
        data (list[float]): éœ€è¦è®¡ç®—é˜ˆå€¼çš„æ•°æ®åˆ—è¡¨ï¼Œä¾‹å¦‚ `body_height`ã€‚
        method (str): é€‰æ‹©è®¡ç®—æ–¹æ³•ï¼Œå¯é€‰å€¼ä¸º 'std', 'mad', 'iqr' (é»˜è®¤ "std")ã€‚
        k (float): ä¹˜æ³•å› å­ï¼Œç”¨äºæ§åˆ¶é˜ˆå€¼çš„çµæ•åº¦ (é»˜è®¤ 2)ã€‚

    è¿”å›ï¼š
        float: è®¡ç®—å‡ºçš„è‡ªé€‚åº”é˜ˆå€¼ã€‚

    å¼‚å¸¸ï¼š
        ValueError: å¦‚æœæä¾›çš„ `method` ä¸æ”¯æŒï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚
    """
    
    # å°†æ•°æ®è½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œç¡®ä¿æ”¯æŒæ•°å­¦è®¡ç®—
    data = np.array(data)
    data = np.array([x if x is not None else 0 for x in data])

    if method == "std":
        # ä½¿ç”¨æ ‡å‡†å·®è®¡ç®—é˜ˆå€¼
        threshold = k * np.std(data)
    
    elif method == "mad":
        # è®¡ç®—ä¸­ä½æ•°
        median = np.median(data)
        # è®¡ç®—å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰
        mad = np.median(np.abs(data - median))
        threshold = k * mad

    elif method == "iqr":
        # è®¡ç®—ç¬¬ä¸€å››åˆ†ä½æ•°ï¼ˆQ1ï¼‰å’Œç¬¬ä¸‰å››åˆ†ä½æ•°ï¼ˆQ3ï¼‰
        Q1 = np.percentile(data, 25)
        Q3 = np.percentile(data, 75)
        # è®¡ç®—å››åˆ†ä½è·ï¼ˆIQRï¼‰
        iqr = Q3 - Q1
        threshold = k * iqr

    else:
        # å¦‚æœä¼ å…¥çš„ `method` å‚æ•°ä¸åˆæ³•ï¼Œåˆ™æŠ›å‡ºé”™è¯¯
        raise ValueError("Unsupported method. Choose from ['std', 'mad', 'iqr']")
    
    return threshold

def detect_change_points(data, percentile=95, window_size=3, visualize=False):
    """
    æ£€æµ‹æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„çªå˜ç‚¹ï¼ˆçªå¢æˆ–çªé™ï¼‰ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. è®¡ç®—æ•°æ®çš„å˜åŒ–ç‡ï¼ˆå–ç»å¯¹å€¼å·®åˆ†ï¼‰ã€‚
    2. æ ¹æ® `percentile` è®¡ç®—çªå˜é˜ˆå€¼ã€‚
    3. ä½¿ç”¨ `find_peaks` æ–¹æ³•æ£€æµ‹è¶…è¿‡é˜ˆå€¼çš„çªå˜ç‚¹ã€‚
    4. è¿‡æ»¤æ‰çŸ­æš‚çªå˜ç‚¹ï¼Œç¡®ä¿å˜åŒ–åç»´æŒé«˜å€¼ä¸€æ®µæ—¶é—´ã€‚
    5. å¦‚æœ `visualize=True`ï¼Œåˆ™ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨ã€‚

    å‚æ•°:
        data (array-like): è¾“å…¥çš„æ—¶é—´åºåˆ—æ•°æ® (å¦‚ body_height)ã€‚
        percentile (float): å˜åŒ–ç‚¹çš„é˜ˆå€¼ï¼ˆåˆ†ä½æ•°ï¼‰ï¼Œé»˜è®¤ 95ï¼ˆå–å‰ 5% æœ€å¤§å˜åŒ–ç‚¹ï¼‰ã€‚
        window_size (int): ç”¨äºè¿‡æ»¤çŸ­æš‚çªå˜ç‚¹çš„çª—å£å¤§å°ï¼ˆé»˜è®¤ 3ï¼‰ã€‚
        visualize (bool): æ˜¯å¦å¯è§†åŒ–æ£€æµ‹ç»“æœï¼Œé»˜è®¤ Trueã€‚

    è¿”å›:
        list[int]: å˜åŒ–ç‚¹çš„ç´¢å¼•åˆ—è¡¨ã€‚

    """

    # ç¡®ä¿æ•°æ®æ˜¯ numpy æ•°ç»„
    data = np.array(data, dtype=float)

    # è®¡ç®—å˜åŒ–ç‡ï¼ˆå–ç»å¯¹å€¼çš„å·®åˆ†ï¼‰
    diff = np.abs(np.diff(data))

    # è®¡ç®—çªå˜ç‚¹é˜ˆå€¼ï¼ˆå–å‰ `percentile%` æœ€å¤§å˜åŒ–å€¼ï¼‰
    threshold = np.percentile(diff, percentile)

    # æ£€æµ‹å˜åŒ–ç‚¹ï¼ˆå³°å€¼ç‚¹ï¼‰
    jump_points, _ = find_peaks(diff, height=threshold)

    # è¿‡æ»¤æ‰çŸ­æš‚çªå˜ç‚¹
    change_points = [
        p for p in jump_points if np.mean(data[p:p + window_size]) > np.mean(data) + np.std(data)
    ]

    # å¯è§†åŒ–æ£€æµ‹ç»“æœ
    if visualize:
        plt.figure(figsize=(12, 5))
        plt.plot(data, label="Data", color="blue")
        plt.scatter(change_points, data[change_points], color='red', label="Change Points", zorder=3)
        plt.legend()
        plt.title("Detected Change Points")
        plt.xlabel("Index")
        plt.ylabel("Value")
        plt.show()

    return change_points

def remove_large_height_changes(change_points, orientation_segments, orientation, body_height, head_y, fps=30, max_duration_sec=90):
    """
    å¤„ç† change_pointsï¼Œåˆ é™¤å¼‚å¸¸çªå˜çš„ç‰‡æ®µã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ threshold**ï¼š
       - é€šè¿‡ `compute_adaptive_threshold()` è®¡ç®— body_height çš„é˜ˆå€¼ï¼Œç”¨äºè¯†åˆ«å¼‚å¸¸å˜åŒ–ã€‚
    2. **éå†æ‰€æœ‰ change_points**ï¼š
       - åœ¨ `max_duration_frames` å†…ï¼Œå¯»æ‰¾æœ€åä¸€ä¸ªå˜åŒ–ç‚¹ã€‚
       - è®¡ç®—è¯¥åŒºé—´çš„ body_height å‡å€¼ï¼Œå¹¶ä¸å…¨å±€å‡å€¼æ¯”è¾ƒã€‚
    3. **åˆ¤æ–­æ˜¯å¦åˆ é™¤è¯¥åŒºé—´**ï¼š
       - è‹¥ body_height çš„çªå˜åŒºåŸŸä¸å…¶ä»–åŒºåŸŸçš„å‡å€¼å·®å€¼å¤§äº thresholdï¼Œåˆ™åˆ é™¤è¯¥ç‰‡æ®µã€‚
       - è‹¥è¯¥çªå˜å‘ç”Ÿåœ¨å‰ 10% æˆ–å 10% çš„è§†é¢‘æ—¶é—´ï¼Œåˆ™ç›´æ¥åˆ é™¤å¯¹åº”åŒºåŸŸã€‚
    4. **åŒæ­¥æ›´æ–° orientation_segmentsã€orientationã€body_height å’Œ head_y**ï¼š
       - åˆ é™¤ç›¸å…³å¸§ï¼Œå¹¶é‡æ–°è®¡ç®—æœ‰æ•ˆçš„ç‰‡æ®µç´¢å¼•ã€‚

    å‚æ•°ï¼š
        change_points (list[int]): æ£€æµ‹åˆ°çš„çªå˜ç‚¹ç´¢å¼•ã€‚
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µã€‚
        orientation (list[str]): æ¯å¸§çš„å§¿æ€ä¿¡æ¯ã€‚
        body_height (list[float]): æ¯å¸§çš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
        head_y (list[float]): æ¯å¸§çš„å¤´éƒ¨ Y åæ ‡æ•°æ®ã€‚
        fps (int): è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤ 30ã€‚
        method (str): è®¡ç®— threshold çš„æ–¹æ³• ["std", "mad", "iqr"]ï¼Œé»˜è®¤ "std"ã€‚
        k (float): è®¡ç®— threshold æ—¶çš„ä¹˜æ³•å› å­ï¼Œé»˜è®¤ 2ã€‚
        max_duration_sec (int): çªå˜æœ€å¤§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 90ã€‚

    è¿”å›ï¼š
        tuple:
            - updated_orientation_segments (list[dict]): æ›´æ–°åçš„å§¿æ€ç‰‡æ®µæ•°æ®ã€‚
            - updated_orientation (list[str]): è¿‡æ»¤åçš„å§¿æ€ä¿¡æ¯ã€‚
            - updated_body_height (list[float]): è¿‡æ»¤åçš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
            - updated_head_y (list[float]): è¿‡æ»¤åçš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
    """

    total_frames = len(body_height)
    max_duration_frames = fps * max_duration_sec

    # è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ threshold
    threshold = compute_adaptive_threshold(body_height)

    frames_to_remove = set()  # è®°å½•éœ€è¦åˆ é™¤çš„å¸§ç´¢å¼•

    # éå†æ‰€æœ‰çªå˜ç‚¹ï¼Œç¡®å®šéœ€è¦åˆ é™¤çš„ç‰‡æ®µ
    for i, cp in enumerate(change_points):
        # å¯»æ‰¾ max_duration_frames å†…çš„æœ€åä¸€ä¸ªçªå˜ç‚¹
        future_changes = [p for p in change_points if p > cp and p <= cp + max_duration_frames]

        end_idx = max(future_changes) if future_changes else cp  # é€‰å–æœ€åçš„çªå˜ç‚¹
        start_idx = cp  # è®°å½•çªå˜åŒºé—´èµ·ç‚¹

        # è®¡ç®—è¯¥åŒºé—´ body_height çš„å‡å€¼
        region_mean = np.mean(body_height[start_idx:end_idx])

        # è®¡ç®—å…¨å±€ body_height å‡å€¼ï¼ˆæ’é™¤è¯¥åŒºé—´ï¼‰
        other_frames = [i for i in range(total_frames) if i < start_idx or i > end_idx]
        if other_frames:
            other_mean = np.mean([body_height[i] for i in other_frames])
        else:
            other_mean = np.mean(body_height)  # ä»…æœ‰è¯¥åŒºé—´å­˜åœ¨ï¼Œå–å…¨å±€å‡å€¼

        # è®¡ç®— body_height çš„å˜åŒ–å¹…åº¦
        height_diff = abs(region_mean - other_mean)

        # å¤„ç†å‰ 10% å’Œå 10% çš„å˜åŒ–
        has_early_change = any(p <= max_duration_frames for p in [start_idx, end_idx])
        has_late_change = any(p >= total_frames - max_duration_frames for p in [start_idx, end_idx])

        if height_diff > threshold:
            if has_early_change:
                # åˆ é™¤å‰ 10% å†…çš„çªå˜åŒºåŸŸ
                frames_to_remove.update(range(0, end_idx + 1))
            elif has_late_change:
                # åˆ é™¤å 10% å†…çš„çªå˜åŒºåŸŸ
                frames_to_remove.update(range(start_idx, total_frames))
            else:
                # åˆ é™¤è¯¥çªå˜åŒºé—´
                frames_to_remove.update(range(start_idx, end_idx + 1))

    # è¿‡æ»¤ orientation_segmentsï¼Œå¹¶åŒæ­¥åˆ é™¤ç›¸åº”å¸§çš„æ•°æ®
    new_frames_to_remove = frames_to_remove.copy()

    updated_orientation_segments = []
    for seg in orientation_segments:
        # å¦‚æœè¯¥ç‰‡æ®µçš„å¸§è¢«æ ‡è®°ä¸ºåˆ é™¤ï¼Œåˆ™ä¸¢å¼ƒ
        if not any(frame in frames_to_remove for frame in range(seg["start_frame"], seg["end_frame"] + 1)):
            updated_orientation_segments.append(seg)
        else:
            new_frames_to_remove.update(range(seg["start_frame"], seg["end_frame"] + 1))

    # é‡æ–°è®¡ç®—æœ‰æ•ˆå¸§ç´¢å¼•
    frames_to_keep = set(range(total_frames)) - new_frames_to_remove
    updated_orientation = [orientation[i] for i in frames_to_keep]
    updated_body_height = [body_height[i] for i in frames_to_keep]
    updated_head_y = [head_y[i] for i in frames_to_keep]

    # é‡æ–°è®¡ç®— orientation_segmentsï¼Œä½¿ç´¢å¼•ä¿æŒè¿ç»­
    if updated_orientation_segments:
        new_segments = []
        prev_end_frame = 0

        for seg in updated_orientation_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)

        updated_orientation_segments = new_segments

    return updated_orientation_segments, updated_orientation, updated_body_height, updated_head_y

def merge_alternating_orients(orientation_segments, fps=30, max_swaps=15, min_duration_sec=3):
    """
    åˆå¹¶çŸ­æ—¶äº¤æ›¿çš„å§¿æ€ç‰‡æ®µï¼Œä»¥å‡å°‘æŠ–åŠ¨å’Œè¯¯åˆ¤ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - å¦‚æœå½“å‰ç‰‡æ®µçš„æ–¹å‘ä¸ä¸Šä¸€ä¸ªç›¸åŒï¼Œåˆ™åˆå¹¶å®ƒä»¬ï¼Œæ›´æ–° `end_frame` å’Œ `duration`ã€‚
    2. **éå†å§¿æ€ç‰‡æ®µï¼Œåˆå¹¶äº¤æ›¿å˜æ¢çš„çŸ­æ—¶ç‰‡æ®µ**ï¼š
       - è®°å½• `swap_count`ï¼Œè·Ÿè¸ªçŸ­æ—¶äº¤æ›¿å‡ºç°çš„æ¬¡æ•°ã€‚
       - å¦‚æœ `swap_count` è¶…è¿‡ `max_swaps`ï¼Œåˆ™åˆå¹¶è¯¥åŒºåŸŸï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ç‰‡æ®µã€‚
       - å¦åˆ™ï¼Œä¿æŒåŸçŠ¶ï¼Œé˜²æ­¢è¿‡åº¦åˆå¹¶ã€‚
    3. **å¤„ç†æœªè¢«åˆå¹¶çš„ç‰‡æ®µ**ï¼š
       - è¿½åŠ æœ€åä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µæ˜¯ä¸€ä¸ªå­—å…¸ã€‚
        fps (int): è§†é¢‘çš„å¸§ç‡ï¼ˆé»˜è®¤ 30ï¼‰ã€‚
        max_swaps (int): å…è®¸çš„æœ€å¤§äº¤æ›¿åˆ‡æ¢æ¬¡æ•°ï¼Œè¶…è¿‡æ­¤å€¼åˆ™è¿›è¡Œåˆå¹¶ï¼ˆé»˜è®¤ 15ï¼‰ã€‚
        min_duration_sec (int): æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå°äºè¯¥å€¼çš„ç‰‡æ®µå°†è¢«åˆå¹¶ï¼ˆé»˜è®¤ 3 ç§’ï¼‰ã€‚

    è¿”å›ï¼š
        list[dict]: å¤„ç†åçš„ `orientation_segments` ç‰‡æ®µåˆ—è¡¨ã€‚
    """

    # **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            # å¦‚æœå½“å‰ç‰‡æ®µä¸ä¸Šä¸€ä¸ªç‰‡æ®µæ–¹å‘ç›¸åŒï¼Œåˆ™åˆå¹¶
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)
    
    # æ›´æ–° `orientation_segments`
    orientation_segments = merged_segments 

    # è®¡ç®—æœ€å°æŒç»­æ—¶é—´ï¼ˆè½¬æ¢ä¸ºå¸§æ•°ï¼‰
    min_duration_frames = fps * min_duration_sec
    result = []
    i = 0  # è¿­ä»£ç´¢å¼•
    
    while i < len(orientation_segments) - 1:
        current_orient = orientation_segments[i]['orient']
        current_frame = orientation_segments[i]['duration_frames']
        if current_frame < min_duration_frames:
            swap_count = 0  # è®°å½•äº¤æ›¿å˜æ¢æ¬¡æ•°
            combined_segments = [orientation_segments[i]]  # å­˜å‚¨å¾…åˆå¹¶ç‰‡æ®µ
            next_orient = orientation_segments[i + 1]['orient']
            next_frame = orientation_segments[i + 1]['duration_frames']
            j = i + 1  # ç”¨äºæ”¶é›†åç»­ç‰‡æ®µçš„ç´¢å¼•
            
            # **å¦‚æœå½“å‰ç‰‡æ®µæ—¶é•¿è¾ƒçŸ­ï¼Œä¸”ä¸‹ä¸€ä¸ªç‰‡æ®µçš„æ–¹å‘ä¸åŒï¼Œåˆ™å°è¯•åˆå¹¶**
            if current_orient != next_orient and next_frame < min_duration_frames:
                combined_segments.append(orientation_segments[j])
                j += 1
                
                # **ç»§ç»­æŸ¥æ‰¾æ›´å¤šçš„çŸ­æ—¶äº¤æ›¿ç‰‡æ®µ**
                while j < len(orientation_segments):
                    third_orient = orientation_segments[j]['orient']
                    third_segment = orientation_segments[j]
                    
                    # **å¦‚æœç¬¬ä¸‰ä¸ªç‰‡æ®µçš„æ–¹å‘å±äº (current_orient, next_orient)ï¼Œä¸”çŸ­æ—¶äº¤æ›¿ï¼Œåˆ™ç»§ç»­åˆå¹¶**
                    if (third_orient in [current_orient, next_orient] and
                        third_orient != combined_segments[-1]['orient'] and
                        third_segment['duration_frames'] < min_duration_frames):
                        swap_count += 1  # è®°å½•äº¤æ›¿åˆ‡æ¢æ¬¡æ•°
                        combined_segments.append(third_segment)
                        j += 1  # ç»§ç»­éå†
                    else:
                        break  # è§„åˆ™è¢«ç ´åï¼Œåœæ­¢åˆå¹¶
                
                # **å¦‚æœäº¤æ›¿åˆ‡æ¢æ¬¡æ•°è¶…è¿‡ `max_swaps`ï¼Œåˆå¹¶è¿™äº›ç‰‡æ®µ**
                if swap_count > max_swaps:
                    combined_orient = f"{current_orient}-{next_orient}"  # ç»„åˆæ–¹å‘
                    merged_segment = {
                        'orient': combined_orient,
                        'start_frame': combined_segments[0]['start_frame'],
                        'end_frame': combined_segments[-1]['end_frame'],
                        'duration_sec': sum(seg['duration_sec'] for seg in combined_segments),
                        'duration_frames': sum(seg['duration_frames'] for seg in combined_segments)
                    }
                    result.append(merged_segment)  # å­˜å‚¨åˆå¹¶åçš„ç‰‡æ®µ
                    print(merged_segment)  # æ‰“å°åˆå¹¶ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                else:
                    result.extend(combined_segments)  # äº¤æ›¿æ¬¡æ•°è¾ƒå°‘ï¼Œä¸åˆå¹¶
                
                # **è·³åˆ°ä¸‹ä¸€ä¸ªæœªå¤„ç†çš„ç‰‡æ®µ**
                i = j  
            else:
                # **å½“å‰ç‰‡æ®µä¸ç¬¦åˆåˆå¹¶æ¡ä»¶ï¼Œç›´æ¥æ·»åŠ åˆ°ç»“æœ**
                result.append(orientation_segments[i])
                i += 1  # ç»§ç»­ä¸»å¾ªç¯éå†
        else:
            # **å½“å‰ç‰‡æ®µä¸ç¬¦åˆåˆå¹¶æ¡ä»¶ï¼Œç›´æ¥æ·»åŠ åˆ°ç»“æœ**
                result.append(orientation_segments[i])
                i += 1  # ç»§ç»­ä¸»å¾ªç¯éå†
    
    # **è¿½åŠ æœ€åä¸€ä¸ª segmentï¼Œå¦‚æœå®ƒæœªè¢«å¤„ç†**
    if i == len(orientation_segments) - 1:
        result.append(orientation_segments[i])
    
    return result

def merge_orientation_segments(orientation_segments, orientation, body_height, head_y, fps=30, min_duration_sec=3, max_duration_sec=15):
    """
    åˆå¹¶çŸ­æ—¶çš„å§¿æ€ç‰‡æ®µï¼Œå»é™¤ä¸ç¨³å®šçš„ç‰‡æ®µï¼Œå¹¶ä¼˜åŒ–æ–¹å‘æ•°æ®ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆå¹¶çŸ­ç‰‡æ®µ**ï¼š
       - å¦‚æœç‰‡æ®µ `duration_frames < min_duration_frames`ï¼Œåˆ™åˆå¹¶åˆ°å‰ä¸€ä¸ªå§¿åŠ¿æ®µï¼Œç›´åˆ°æ‰€æœ‰çŸ­ç‰‡æ®µè¢«åˆå¹¶å®Œæ¯•ã€‚
    2. **åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - å¦‚æœç›¸é‚»ç‰‡æ®µçš„ `orient` ç›¸åŒï¼Œåˆ™åˆå¹¶ã€‚
    3. **ç§»é™¤æ—¶é•¿å°äº max_duration_sec çš„é¦–å°¾ç‰‡æ®µ**ï¼š
       - å¦‚æœé¦–å°¾ç‰‡æ®µçš„ `duration_frames < max_duration_frames`ï¼Œåˆ™åˆ é™¤è¯¥ç‰‡æ®µçš„å¸§æ•°æ®ã€‚
    4. **è°ƒæ•´çŸ­ç‰‡æ®µçš„å§¿åŠ¿**ï¼š
       - å¦‚æœç‰‡æ®µ `duration_frames < max_duration_frames`ï¼Œå¹¶ä¸”å®ƒçš„å‰åç‰‡æ®µæ–¹å‘ç›¸åŒï¼Œåˆ™è®¾ä¸ºè¯¥æ–¹å‘ï¼Œå¦åˆ™è®¾ä¸ºå‰ä¸€ä¸ªæ–¹å‘ã€‚
    5. **å†æ¬¡åˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**ï¼š
       - é¿å…å› è°ƒæ•´å§¿åŠ¿åäº§ç”Ÿçš„é‡å¤ç‰‡æ®µã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µæ˜¯ä¸€ä¸ªå­—å…¸ã€‚
        orientation (list[str]): æ¯å¸§çš„å§¿æ€ä¿¡æ¯ã€‚
        body_height (list[float]): æ¯å¸§çš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
        head_y (list[float]): æ¯å¸§çš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
        fps (int): è§†é¢‘çš„å¸§ç‡ï¼ˆé»˜è®¤ 30ï¼‰ã€‚
        min_duration_sec (int): æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå°äºè¯¥å€¼çš„ç‰‡æ®µå°†è¢«åˆå¹¶ï¼ˆé»˜è®¤ 3 ç§’ï¼‰ã€‚
        max_duration_sec (int): æœ€å¤§åˆå¹¶æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡è¯¥å€¼çš„ç‰‡æ®µæ‰ä¼šè¢«ä¿ç•™ï¼ˆé»˜è®¤ 15 ç§’ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - orientation_segments (list[dict]): å¤„ç†åçš„å§¿æ€ç‰‡æ®µã€‚
            - orientation (list[str]): è¿‡æ»¤åçš„å§¿æ€ä¿¡æ¯ã€‚
            - body_height (list[float]): è¿‡æ»¤åçš„èº«ä½“é«˜åº¦æ•°æ®ã€‚
            - head_y (list[float]): è¿‡æ»¤åçš„å¤´éƒ¨ Y è½´æ•°æ®ã€‚
    """

    # **è®¡ç®—å¸§æ•°é˜ˆå€¼**
    min_duration_frames = fps * min_duration_sec
    max_duration_frames = fps * max_duration_sec

    # **ç¬¬ä¸€æ­¥ï¼šåˆå¹¶çŸ­ç‰‡æ®µï¼Œç›´åˆ°æ‰€æœ‰çŸ­ç‰‡æ®µè¢«åˆå¹¶å®Œæ¯•**
    final_segments = orientation_segments[:]
    while True:
        updated_segments = []
        merged = False  # è®°å½•æ˜¯å¦å‘ç”Ÿäº†åˆå¹¶

        for i, segment in enumerate(final_segments):
            if updated_segments and segment["duration_frames"] < min_duration_frames:
                # **å°†çŸ­ç‰‡æ®µåˆå¹¶åˆ°å‰ä¸€ä¸ªå§¿åŠ¿æ®µ**
                updated_segments[-1]["end_frame"] = segment["end_frame"]
                updated_segments[-1]["duration_sec"] = (
                    updated_segments[-1]["end_frame"] - updated_segments[-1]["start_frame"] + 1
                ) / fps
                updated_segments[-1]["duration_frames"] = (
                    updated_segments[-1]["end_frame"] - updated_segments[-1]["start_frame"] + 1
                )
                merged = True  # è®°å½•åˆå¹¶å‘ç”Ÿ
            else:
                updated_segments.append(segment)

        if not merged:
            break  # æ²¡æœ‰å‘ç”Ÿåˆå¹¶ï¼Œè·³å‡ºå¾ªç¯
        
        final_segments = updated_segments
        orientation_segments = final_segments  # æ›´æ–° segments

    # **ç¬¬äºŒæ­¥ï¼šåˆå¹¶ç›¸é‚»çš„ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            # **åˆå¹¶ç›¸é‚»ç›¸åŒå§¿åŠ¿ç‰‡æ®µ**
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)
    
    orientation_segments = merged_segments  # æ›´æ–° segments

    frames_to_remove = set()  # è®°å½•è¦åˆ é™¤çš„å¸§

     # ä»å¤´å¼€å§‹éå†
    while orientation_segments:
        first_segment = orientation_segments[0]
        if first_segment['duration_frames'] < max_duration_frames:
            print(f"ğŸ—‘ åˆ é™¤å¤´éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {first_segment}")
            frames_to_remove.update(range(first_segment['start_frame'], first_segment['end_frame'] + 1))
            orientation_segments.pop(0)
        else:
            break  # é‡åˆ°ç¬¦åˆè¦æ±‚çš„ç‰‡æ®µï¼Œåœæ­¢ä»å¤´éƒ¨éå†

    # ä»å°¾éƒ¨å¼€å§‹éå†
    while orientation_segments:
        last_segment = orientation_segments[-1]
        if last_segment['duration_frames'] < max_duration_frames:
            print(f"ğŸ—‘ åˆ é™¤å°¾éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {last_segment}")
            frames_to_remove.update(range(last_segment['start_frame'], last_segment['end_frame'] + 1))
            orientation_segments.pop(-1)
        else:
            break  # é‡åˆ°ç¬¦åˆè¦æ±‚çš„ç‰‡æ®µï¼Œåœæ­¢ä»å°¾éƒ¨éå†

     # **ç¬¬å››æ­¥ï¼šåˆ é™¤æœ€åä¸€ä¸ªå°äº max_duration_sec çš„ç‰‡æ®µ**
    if orientation_segments and orientation_segments[-1]["duration_frames"] < 2 * max_duration_frames and orientation_segments[-1]['orient'] == 'neutral':
        last_segment = orientation_segments[-1]
        print(f"ğŸ—‘ åˆ é™¤å°¾éƒ¨ç‰‡æ®µ (å°äº {max_duration_sec} ç§’): {last_segment}")
        frames_to_remove.update(range(last_segment["start_frame"], last_segment["end_frame"] + 1))
        orientation_segments.pop(-1)  # åˆ é™¤ç‰‡æ®µ

    # **ç¬¬äº”æ­¥ï¼šåˆ é™¤ `orientation`ã€`body_height` å’Œ `head_y` ä¸­çš„ç›¸åº”å¸§**
    orientation = [orient for i, orient in enumerate(orientation) if i not in frames_to_remove]
    body_height = [height for i, height in enumerate(body_height) if i not in frames_to_remove]
    head_y = [head_y for i, head_y in enumerate(head_y) if i not in frames_to_remove]

    # **ç¬¬å…­æ­¥ï¼šé‡æ–°è°ƒæ•´ segment ç´¢å¼•**
    if orientation_segments:
        new_segments = []
        prev_end_frame = 0
        
        for seg in orientation_segments:
            duration = seg["end_frame"] - seg["start_frame"]
            seg["start_frame"] = prev_end_frame
            seg["end_frame"] = prev_end_frame + duration
            prev_end_frame = seg["end_frame"] + 1
            new_segments.append(seg)
        
        orientation_segments = new_segments  # æ›´æ–° segments

    # **ç¬¬ä¸ƒæ­¥ï¼šè°ƒæ•´çŸ­ç‰‡æ®µçš„æ–¹å‘**
    for i in range(1, len(orientation_segments) - 1):  # é¿å…è®¿é—®è¶…å‡ºèŒƒå›´
        segment = orientation_segments[i]

        if segment["duration_frames"] < max_duration_frames:
            prev_orient = orientation_segments[i - 1]["orient"]

            # **å¦‚æœå‰åå§¿åŠ¿ç›¸åŒï¼Œåˆ™è®¾ä¸ºè¯¥å§¿åŠ¿ï¼Œå¦åˆ™è®¾ä¸ºå‰ä¸€ä¸ªç‰‡æ®µçš„å§¿åŠ¿**
            segment["orient"] = prev_orient

    # **ç¬¬å…«æ­¥ï¼šå†æ¬¡åˆå¹¶ç›¸é‚»ç›¸åŒå§¿åŠ¿**
    merged_segments = []
    for segment in orientation_segments:
        if merged_segments and merged_segments[-1]["orient"] == segment["orient"]:
            merged_segments[-1]["end_frame"] = segment["end_frame"]
            merged_segments[-1]["duration_sec"] = (merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1) / fps
            merged_segments[-1]["duration_frames"] = merged_segments[-1]["end_frame"] - merged_segments[-1]["start_frame"] + 1
        else:
            merged_segments.append(segment)

    orientation_segments = merged_segments  # æ›´æ–° segments
    
    return orientation_segments, orientation, body_height, head_y

def split_head_y_by_orientation(orientation_segments, head_y):
    """
    æ ¹æ® orientation_segments ä¸­çš„ start_frame å’Œ end_frameï¼Œåˆ†å‰² head_y æ•°æ®ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **éå† orientation_segments**ï¼š
       - æ¯ä¸ªç‰‡æ®µåŒ…å« `start_frame` å’Œ `end_frame`ï¼Œç”¨äºç¡®å®šæ•°æ®åˆ†å‰²èŒƒå›´ã€‚
    2. **æå– head_y ç‰‡æ®µ**ï¼š
       - å– `head_y[start:end+1]`ï¼Œç¡®ä¿ `end_frame` å¯¹åº”çš„å¸§ä¹Ÿè¢«åŒ…å«åœ¨å†…ã€‚
    3. **å­˜å‚¨åˆ†å‰²åçš„ head_y ç‰‡æ®µ**ï¼š
       - å°†åˆ‡ç‰‡ç»“æœå­˜å…¥ `segmented_head_y` åˆ—è¡¨ä¸­ï¼Œä¿æŒç´¢å¼•ä¸€è‡´ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ä¿¡æ¯ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å« `start_frame` å’Œ `end_frame`ã€‚
        head_y (list[float]): å¤´éƒ¨ Y åæ ‡æ•°æ®åˆ—è¡¨ã€‚

    è¿”å›ï¼š
        list[list[float]]: åˆ†å‰²åçš„ head_y ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªç‰‡æ®µå¯¹åº”ä¸€ä¸ª `orientation_segments` ç‰‡æ®µã€‚
    """

    segmented_head_y = []  # å­˜å‚¨åˆ†å‰²åçš„ head_y ç‰‡æ®µ
    
    for segment in orientation_segments:
        start = segment['start_frame']
        end = segment['end_frame'] + 1  # åŒ…å« `end_frame` æ‰€åœ¨çš„ç´¢å¼•
        head_y_segment = head_y[start:end]  # æå–å¯¹åº”çš„ head_y æ•°æ®
        
        segmented_head_y.append(head_y_segment)

    return segmented_head_y

def process_segmented_head_y(segmented_head_y, frame_window=400, max_timestamps=8, smooth_window=5, max_iterations=10):
    """
    å¤„ç† segmented_head_yï¼Œè¿­ä»£æ£€æµ‹çªå˜ç‚¹ï¼Œåˆ†å‰²æ•°æ®ï¼Œæ¸…ç†æ— æ•ˆæ•°æ®ï¼Œå¹¶å¹³æ»‘æ–­ç‚¹ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è¿­ä»£å¤„ç†æ•°æ®**ï¼ˆæœ€å¤š `max_iterations` æ¬¡ï¼‰ï¼š
       - é€ä¸ªæ£€æŸ¥ `segmented_head_y`ï¼Œç§»é™¤çŸ­ç‰‡æ®µï¼Œå¹¶æ£€æµ‹çªå˜ç‚¹ã€‚
    2. **æ£€æµ‹å¹¶æ ‡è®°çªå˜ç‚¹**ï¼š
       - è®¡ç®— `threshold` ä½œä¸ºå˜åŒ–æ£€æµ‹æ ‡å‡†ã€‚
       - ä½¿ç”¨ `ruptures` è¿›è¡Œçªå˜ç‚¹æ£€æµ‹ï¼Œè¯†åˆ«æ˜¾è‘—å˜åŒ–åŒºåŸŸã€‚
    3. **å»é™¤æ— æ•ˆæ•°æ®**ï¼š
       - è‹¥çªå˜ç‚¹åœ¨å‰ `frame_window` å¸§æˆ–å `frame_window` å¸§ï¼Œåˆ™æ ‡è®°ä¸ºæ— æ•ˆã€‚
       - å¯¹ç›¸é‚»çªå˜ç‚¹è¿›è¡Œåˆå¹¶ï¼Œå‡å°‘è¯¯åˆ¤ã€‚
       - è‹¥çªå˜ç‚¹æ•°é‡è¶…è¿‡ `max_timestamps`ï¼Œè·³è¿‡è¯¥æ®µæ•°æ®ï¼Œé˜²æ­¢è¯¯åˆ†å‰²ã€‚
    4. **åˆ†å‰²æ•°æ®**ï¼š
       - ä¾æ®çªå˜ç‚¹å¯¹æ•°æ®è¿›è¡Œåˆ†å‰²ï¼Œé¿å…æ•°æ®æ··ä¹±ã€‚
       - è‹¥ç›¸é‚»çªå˜ç‚¹é—´è·è¿‡çŸ­ï¼Œåˆ™è·³è¿‡åˆ†å‰²ï¼Œä»¥é¿å…ç¢ç‰‡åŒ–ã€‚
    5. **å¹³æ»‘æ•°æ®**ï¼š
       - å¯¹äºæ¯ä¸ªåˆ†å‰²ç‰‡æ®µï¼Œä½¿ç”¨ `savgol_filter` è¿›è¡Œå¹³æ»‘ï¼Œä»¥å‡å°‘å™ªå£°ã€‚
    6. **ç»ˆæ­¢æ¡ä»¶**ï¼š
       - è‹¥æ•°æ®åœ¨æŸæ¬¡è¿­ä»£åä¸å†å‘ç”Ÿå˜åŒ–ï¼Œåˆ™ç»ˆæ­¢è¿­ä»£ï¼Œé¿å…æ— é™å¾ªç¯ã€‚

    å‚æ•°ï¼š
        segmented_head_y (list of list): å¤´éƒ¨ Y è½´æ•°æ®ï¼Œæ¯ä¸ªå­åˆ—è¡¨è¡¨ç¤ºä¸€ä¸ªæ—¶é—´åºåˆ—ç‰‡æ®µã€‚
        frame_window (int): ç”¨äºæ£€æµ‹çªå˜ç‚¹çš„å‰åçª—å£å¤§å°ï¼ˆé»˜è®¤ 400 å¸§ï¼‰ã€‚
        max_timestamps (int): å…è®¸çš„æœ€å¤§çªå˜ç‚¹æ•°é‡ï¼Œè¶…å‡ºåˆ™è·³è¿‡è¯¥æ®µæ•°æ®ï¼ˆé»˜è®¤ 8ï¼‰ã€‚
        smooth_window (int): å¹³æ»‘çª—å£å¤§å°ï¼ˆé»˜è®¤ 5ï¼‰ã€‚
        max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯ï¼ˆé»˜è®¤ 10ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - processed_data (list of list): å¤„ç†åçš„åˆ†å‰²æ•°æ®ã€‚
            - split_info (list): è®°å½• `segmented_head_y` çš„ç¬¬å‡ ä¸ªå…ƒç´ è¢«åˆ†å‰²å‡ æ¬¡ã€‚
    """

    # **åˆå§‹è¾“å…¥**
    processed_data = segmented_head_y
    split_info = list(range(len(segmented_head_y)))  # è®°å½•åˆå§‹ç´¢å¼•
    iteration = 0

    while iteration < max_iterations:
        iteration += 1
        new_processed_data = []
        new_split_info = []

        has_changes = False  # è¿½è¸ªæ˜¯å¦æœ‰æ–°çš„åˆ†å‰²æˆ–æ•°æ®æ¸…ç†

        for idx, segment in zip(split_info, processed_data):
            if len(segment) < 2 * frame_window:  # **æ•°æ®è¿‡çŸ­ï¼Œåˆ™è·³è¿‡**
                new_processed_data.append(segment)
                new_split_info.append(idx)
                continue

            segment = np.array(segment, dtype=float)

            # âœ… **1. è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼**
            threshold = compute_adaptive_threshold(segment, "std", 1)

            # âœ… **2. æ£€æµ‹çªå˜ç‚¹**
            algo = rpt.Pelt(model="l2").fit(segment)
            change_points = algo.predict(pen=1)  # è·å–çªå˜ç‚¹ç´¢å¼•

            # âœ… **3. å¤„ç†çªå˜ç‚¹**
            invalid_indices = set()
            timestamps = []
            middle_timestamps = []  # è®°å½•ä¸­é—´çªå˜ç‚¹ï¼ˆæ’é™¤å‰ 400 å¸§å’Œå 400 å¸§ï¼‰

            for cp in change_points:
                if cp < frame_window:  # **å‰ 400 å¸§å†…**
                    before_mean = np.mean(segment[:cp])
                    after_mean = np.mean(segment[cp:cp + frame_window])
                    if abs(after_mean - before_mean) > threshold:
                        invalid_indices.update(range(0, cp + frame_window))

                elif cp > len(segment) - frame_window:  # **å 400 å¸§å†…**
                    before_mean = np.mean(segment[cp - frame_window:cp])
                    after_mean = np.mean(segment[cp:])
                    if abs(after_mean - before_mean) > threshold:
                        invalid_indices.update(range(cp - frame_window, len(segment)))

                else:  # **ä¸­é—´éƒ¨åˆ†**
                    before_mean = np.mean(segment[cp - frame_window:cp])
                    after_mean = np.mean(segment[cp:cp + frame_window])
                    if abs(after_mean - before_mean) > threshold:
                        timestamps.append(cp)
                        middle_timestamps.append(cp)  # è®°å½•ä¸­é—´éƒ¨åˆ†çªå˜ç‚¹

            # âœ… **4. å¤„ç†ä¸­é—´çš„çªå˜ç‚¹**
            if len(middle_timestamps) > max_timestamps:
                print(f"Skipping segment {idx} due to too many middle timestamps: {len(middle_timestamps)}")
                timestamps = []  # æ¸…ç©ºçªå˜ç‚¹ï¼Œé¿å…è¯¯åˆ†å‰²

            # âœ… **5. å¤„ç†ç›¸é‚»çªå˜ç‚¹**
            new_timestamps = []
            last_cp = None

            for cp in timestamps:
                if last_cp is not None and (cp - last_cp) < frame_window:
                    invalid_indices.update(range(last_cp, cp))  # æ ‡è®°è¯¥æ•°æ®æ— æ•ˆ
                else:
                    new_timestamps.append(cp)
                    last_cp = cp
            timestamps = new_timestamps  # **æ›´æ–° timestamps**

            # âœ… **6. å»é™¤æ— æ•ˆæ•°æ®**
            valid_indices = sorted(set(range(len(segment))) - invalid_indices)
            filtered_segment = segment[valid_indices]  # ä»…ä¿ç•™æœ‰æ•ˆæ•°æ®

            if len(valid_indices) < len(segment):  # **æ•°æ®è¢«ä¿®æ”¹**
                has_changes = True

            # âœ… **7. åˆ†å‰²æ•°æ®**
            split_segments = []
            last_cp = 0
            for cp in timestamps:
                if cp - last_cp > 10:  # **é¿å…åˆ†å‰²å¤ªçŸ­**
                    split_segments.append(filtered_segment[last_cp:cp])
                    new_split_info.append(idx)
                last_cp = cp

            if last_cp < len(filtered_segment):  # **æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ**
                split_segments.append(filtered_segment[last_cp:])
                new_split_info.append(idx)

            if len(split_segments) > 1:  # **å‘ç”Ÿäº†åˆ†å‰²**
                has_changes = True

            # âœ… **8. å¹³æ»‘æ–­ç‚¹**
            final_segments = []
            for sub_segment in split_segments:
                if len(sub_segment) > smooth_window:
                    sub_segment = savgol_filter(sub_segment, smooth_window, polyorder=2)
                final_segments.append(sub_segment)

            new_processed_data.extend(final_segments)

        # **æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å˜åŒ–**
        if not has_changes:
            print(f"Converged after {iteration} iterations.")
            break

        # **æ›´æ–° processed_data å’Œ split_info**
        processed_data = new_processed_data
        split_info = new_split_info

    return processed_data, split_info

def detect_periodicity_acf_with_peaks(data, threshold=0.2, max_lag=300, min_ratio=0.4, min_alternations=6):
    """
    ä½¿ç”¨è‡ªç›¸å…³å‡½æ•° (ACF) æ£€æµ‹æ—¶é—´åºåˆ—æ˜¯å¦å…·æœ‰å‘¨æœŸæ€§ï¼Œå¹¶è®¡ç®—æœ€é«˜å³°å€¼å’Œæœ€ä½å³°å€¼ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®— ACFï¼ˆè‡ªç›¸å…³å‡½æ•°ï¼‰**ï¼š
       - è®¡ç®— `max_lag` å†…çš„è‡ªç›¸å…³å€¼ï¼Œç”¨äºåˆ†ææ•°æ®çš„å‘¨æœŸæ€§ã€‚
    2. **ç»Ÿè®¡æ»åæ­¥é•¿ä¸­æ˜¾è‘—ç›¸å…³çš„æ¯”ä¾‹**ï¼š
       - è®¡ç®— `|ACF| > threshold` çš„æ»åå€¼å æ¯” `ratio`ã€‚
    3. **è®¡ç®— ACF çš„ç¬¦å·å˜åŒ–**ï¼š
       - è®¡ç®— `sign_changes`ï¼ˆACF çš„æ­£è´Ÿå·ï¼‰ã€‚
       - è®¡ç®— `alternation_count`ï¼ˆACF çš„æ­£è´Ÿäº¤æ›¿æ¬¡æ•°ï¼‰ã€‚
    4. **åˆ¤æ–­å‘¨æœŸæ€§**ï¼š
       - åªæœ‰å½“ `ratio > min_ratio` ä¸” `alternation_count >= min_alternations` æ—¶ï¼Œè®¤ä¸ºæ•°æ®å…·æœ‰å‘¨æœŸæ€§ã€‚
    5. **è®¡ç®—å‡å€¼å’ŒæŒ¯å¹…**ï¼š
       - è®¡ç®—æ•°æ®çš„ `mean`ã€‚
       - è®¡ç®— `amp`ï¼ˆæ•°æ®çš„ FFT æŒ¯å¹…ï¼Œéœ€è°ƒç”¨ `compute_amplitude_fft`ï¼‰ã€‚

    å‚æ•°ï¼š
        data (array-like): æ—¶é—´åºåˆ—æ•°æ®ã€‚
        threshold (float): è‡ªç›¸å…³ç³»æ•°é˜ˆå€¼ï¼Œç»å¯¹å€¼å¤§äºæ­¤å€¼æ‰ç®—æ˜¾è‘—ç›¸å…³ï¼ˆé»˜è®¤ 0.2ï¼‰ã€‚
        max_lag (int): è®¡ç®— ACF æ—¶çš„æœ€å¤§æ»åæ­¥é•¿ï¼ˆé»˜è®¤ 300ï¼‰ã€‚
        min_ratio (float): å¤šå°‘æ¯”ä¾‹çš„æ»åå€¼éœ€è¦è¶…è¿‡ `threshold` æ‰ç®—å‘¨æœŸæ€§ï¼ˆé»˜è®¤ 0.4ï¼‰ã€‚
        min_alternations (int): è‡³å°‘å¤šå°‘æ¬¡æ­£è´Ÿäº¤æ›¿æ‰ç®—å‘¨æœŸæ€§ï¼ˆé»˜è®¤ 6ï¼‰ã€‚

    è¿”å›ï¼š
        tuple:
            - periodic (bool): æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§ã€‚
            - mean (float): æ•°æ®å‡å€¼ã€‚
            - amp (float): æ•°æ®çš„ FFT æŒ¯å¹…ã€‚
    """

    # **è®¡ç®— ACF**
    acf_values = sm.tsa.acf(data, nlags=max_lag)

    # **ç»Ÿè®¡ |ACF| è¶…è¿‡ threshold çš„æ»åç‚¹æ•°é‡**
    above_threshold = np.sum(np.abs(acf_values[1:]) > threshold)  # ç»Ÿè®¡æ˜¾è‘—ç›¸å…³çš„ç‚¹
    ratio = above_threshold / max_lag  # è®¡ç®—å æ¯”

    # **è®¡ç®— ACF çš„æ­£è´Ÿå˜åŒ–**
    sign_changes = np.sign(acf_values[1:])  # è·å– ACF çš„æ­£è´Ÿå· (+1 æˆ– -1)
    alternation_count = np.sum(np.diff(sign_changes) != 0)  # è®¡ç®—æ­£è´Ÿäº¤æ›¿æ¬¡æ•°

    # **åˆ¤æ–­å‘¨æœŸæ€§**
    periodic = (ratio > min_ratio) and (alternation_count >= min_alternations)

    # **è®¡ç®—å‡å€¼**
    mean = np.mean(data)

    # **è®¡ç®—æ•°æ®çš„ FFT æŒ¯å¹…**
    amp = compute_amplitude_fft(data)  # éœ€è¦ `compute_amplitude_fft()` æ–¹æ³•æ”¯æŒ

    return periodic, mean, amp

def split_orientation_segments(orientation_segments, segmented_head_y, split_info):
    """
    æ ¹æ® segmented_head_y å’Œ split_info å¯¹ orientation_segments è¿›è¡Œç›¸åº”çš„åˆ†å‰²ï¼Œ
    å¹¶æŒ‰æ¯”ä¾‹åˆ†é…å¸§æ•°ï¼Œä»¥ä¿æŒæ•°æ®å®Œæ•´æ€§ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®—åŸå§‹ç‰‡æ®µçš„ frame åˆ†é…æƒ…å†µ**ï¼š
       - è®°å½•æ¯ä¸ª `orientation_segments` ç‰‡æ®µå¯¹åº”çš„ `segmented_head_y` ç‰‡æ®µæ€»é•¿åº¦ (`segment_lengths`)ã€‚
    2. **éå† segmented_head_y å¹¶è¿›è¡Œåˆ†å‰²**ï¼š
       - æŒ‰æ¯”ä¾‹è®¡ç®—æ–°çš„ `duration_frames`ï¼Œç¡®ä¿å¸§æ•°åˆ†é…åˆç†ã€‚
       - ç¡®ä¿ `start_frame` å’Œ `end_frame` è¿ç»­ï¼Œé¿å…æ•°æ®ä¸è¿è´¯ã€‚
    3. **ç”Ÿæˆæ–°ç‰‡æ®µ**ï¼š
       - è®¡ç®—æ–°çš„ `duration_sec`ï¼Œä¿æŒ `FPS` ä¸€è‡´ã€‚
       - åˆ›å»ºæ–°çš„ `orientation_segments`ï¼Œå­˜å‚¨åœ¨ `new_segments` åˆ—è¡¨ä¸­ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): åŸå§‹å§¿æ€ç‰‡æ®µï¼Œæ¯ä¸ªå­—å…¸åŒ…å«:
            - "orient": å§¿æ€æ–¹å‘
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•
            - "duration_sec": ç‰‡æ®µæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            - "duration_frames": ç‰‡æ®µæŒç»­å¸§æ•°
        segmented_head_y (list[list[float]]): åˆ†å‰²åçš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ¯ä¸ªå­åˆ—è¡¨å¯¹åº”ä¸€ä¸ªåˆ†å‰²éƒ¨åˆ†ã€‚
        split_info (list[int]): æŒ‡ç¤º `segmented_head_y` æ¯ä¸ªå…ƒç´ å±äºå“ªä¸ª `orientation_segments` ç‰‡æ®µã€‚

    è¿”å›ï¼š
        list[dict]: é‡æ–°åˆ†å‰²åçš„ `orientation_segments` ç‰‡æ®µåˆ—è¡¨ã€‚
    """

    new_segments = []

    # è®°å½•æ¯ä¸ªåŸå§‹ç‰‡æ®µçš„ frame åˆ†é…æƒ…å†µ
    segment_allocations = {}  

    # è®¡ç®—æ¯ä¸ª segment_index å…³è”çš„ segmented_head_y ç‰‡æ®µæ€»é•¿åº¦
    segment_lengths = {}
    for i, segment_data in enumerate(segmented_head_y):
        segment_index = split_info[i]
        segment_lengths[segment_index] = segment_lengths.get(segment_index, 0) + len(segment_data)

    # éå† segmented_head_y å¹¶è¿›è¡Œåˆ†å‰²
    for i, segment_data in enumerate(segmented_head_y):
        segment_index = split_info[i]  # è¯¥æ•°æ®ç‰‡æ®µå±äºå“ªä¸ªåŸ `orientation_segments` ç‰‡æ®µ
        orig_segment = orientation_segments[segment_index]  # è·å–åŸå§‹ `orientation_segments` ç‰‡æ®µ

        # è·å–åŸå§‹ç‰‡æ®µçš„ä¿¡æ¯
        orig_start_frame = orig_segment["start_frame"]
        orig_duration_frames = orig_segment["duration_frames"]

        # æŒ‰æ¯”ä¾‹è®¡ç®—æ–°çš„ `duration_frames`
        total_segment_length = segment_lengths[segment_index]  # è¯¥ç‰‡æ®µæ‰€æœ‰ `segmented_head_y` æ•°æ®æ€»é•¿åº¦
        ratio = len(segment_data) / total_segment_length
        new_duration_frames = round(ratio * orig_duration_frames)

        # ç¡®ä¿ç‰‡æ®µæ˜¯è¿ç»­çš„
        if segment_index not in segment_allocations:
            segment_allocations[segment_index] = orig_start_frame
        start_frame = segment_allocations[segment_index]
        end_frame = start_frame + new_duration_frames - 1

        # è®¡ç®—å¸§ç‡ (FPS) ä»¥è½¬æ¢ `duration_frames -> duration_sec`
        fps = orig_segment["duration_sec"] / orig_duration_frames
        duration_sec = new_duration_frames * fps

        # ç”Ÿæˆæ–°ç‰‡æ®µ
        new_segment = {
            "orient": orig_segment["orient"],
            "start_frame": start_frame,
            "end_frame": end_frame,
            "duration_sec": duration_sec,
            "duration_frames": new_duration_frames,
        }
        new_segments.append(new_segment)

        # æ›´æ–°èµ·å§‹ä½ç½®ï¼Œç¡®ä¿ä¸‹ä¸€ç‰‡æ®µçš„ `start_frame` è¿ç»­
        segment_allocations[segment_index] = end_frame + 1

    return new_segments

def compute_amplitude_fft(time_series):
    """
    è®¡ç®—ä¸»é¢‘åŠå…¶å¯¹åº”çš„æŒ¯å¹…ï¼ˆåŸºäº FFTï¼‰ã€‚

    ä¸»è¦é€»è¾‘ï¼š
    1. **è®¡ç®— FFTï¼ˆå¿«é€Ÿå‚…é‡Œå¶å˜æ¢ï¼‰**ï¼š
       - è·å– `time_series` çš„é¢‘è°±ä¿¡æ¯ã€‚
    2. **è®¡ç®—æŒ¯å¹…è°±**ï¼š
       - å½’ä¸€åŒ–è®¡ç®—æŒ¯å¹…ï¼Œä½¿å¾—æŒ¯å¹…å¤§å°ç‹¬ç«‹äºæ•°æ®é•¿åº¦ã€‚
    3. **è·å–ä¸»é¢‘çš„æŒ¯å¹…**ï¼š
       - ä»…ä½¿ç”¨æ­£é¢‘ç‡éƒ¨åˆ†ï¼ˆFFT ç»“æœçš„å‰åŠéƒ¨åˆ†ï¼‰ã€‚
       - å¿½ç•¥é›¶é¢‘ï¼ˆç›´æµåˆ†é‡ï¼‰ï¼Œæ‰¾åˆ°æŒ¯å¹…æœ€å¤§çš„é¢‘ç‡åˆ†é‡ã€‚

    å‚æ•°ï¼š
        time_series (array-like): è¾“å…¥çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚

    è¿”å›ï¼š
        float: ä¸»é¢‘å¯¹åº”çš„æŒ¯å¹…ã€‚
    """

    N = len(time_series)  # **æ•°æ®é•¿åº¦**
    fft_values = np.fft.fft(time_series)  # **è®¡ç®— FFT**
    
    # **è®¡ç®—æŒ¯å¹…è°±ï¼ˆå½’ä¸€åŒ–å¤„ç†ï¼‰**
    amplitude_spectrum = (2 / N) * np.abs(fft_values)  # **æŒ¯å¹…å½’ä¸€åŒ–**

    # **å–æ­£é¢‘ç‡éƒ¨åˆ†ï¼ˆå»æ‰è´Ÿé¢‘ç‡ï¼‰**
    positive_amplitude = amplitude_spectrum[:N // 2]

    # **æ‰¾åˆ°ä¸»é¢‘ç´¢å¼•ï¼ˆå¿½ç•¥é›¶é¢‘ï¼‰**
    main_freq_index = np.argmax(positive_amplitude[1:]) + 1  # **è·³è¿‡ç›´æµåˆ†é‡ï¼ˆDCï¼‰**
    main_amplitude = positive_amplitude[main_freq_index]

    return main_amplitude

def update_orientation_segments(orientation_segments, periodics, means, amps):
    """
    æ ¹æ® `periodics`ã€`means` å’Œ `amps` æ›´æ–° `orientation_segments`ï¼Œæ·»åŠ  `head_y` å€¼ï¼š
    
    ä¸»è¦é€»è¾‘ï¼š
    1. **åˆ¤æ–­æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§**ï¼š
       - è‹¥ `periodics[i] == True`ï¼Œåˆ™ `head_y = [means[i] - amps[i], means[i] + amps[i]]`ã€‚
       - è‹¥ `periodics[i] == False`ï¼Œåˆ™ `head_y = means[i]`ï¼ˆæ— æ˜æ˜¾å‘¨æœŸæ€§ï¼Œç›´æ¥èµ‹å€¼ï¼‰ã€‚
    2. **æ›´æ–° `orientation_segments`**ï¼š
       - éå† `orientation_segments`ï¼Œä¸ºæ¯ä¸ªç‰‡æ®µè®¡ç®— `head_y` å¹¶å­˜å…¥å­—å…¸ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å¾…æ›´æ–°çš„å§¿æ€ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - "orient": å§¿æ€æ–¹å‘
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•
            - "duration_sec": ç‰‡æ®µæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            - "duration_frames": ç‰‡æ®µæŒç»­å¸§æ•°
        periodics (list[bool]): æ˜¯å¦å­˜åœ¨å‘¨æœŸæ€§ (True / False)ã€‚
        means (list[float]): æ¯ä¸ªç‰‡æ®µçš„å‡å€¼ã€‚
        amps (list[float]): æ¯ä¸ªç‰‡æ®µçš„æŒ¯å¹…ï¼ˆå‘¨æœŸæ€§æŒ¯å¹…ï¼‰ã€‚

    è¿”å›ï¼š
        list[dict]: åŒ…å« `head_y` ä¿¡æ¯çš„ `orientation_segments`ã€‚
    """

    for i in range(len(orientation_segments)):
        if periodics[i]:
            orientation_segments[i]["head_y"] = [means[i] - amps[i], means[i] + amps[i]]  # **è®¾å®šåŒºé—´**
        else:
            orientation_segments[i]["head_y"] = means[i]  # **æ— å‘¨æœŸæ€§ï¼Œç›´æ¥èµ‹å€¼**

    return orientation_segments

def plot_orientation_segments(orientation_segments, save_path):
    """
    ç»˜åˆ¶ `head_y` å˜åŒ–ï¼ˆåŸºäº `orientation_segments["head_y"]`ï¼‰å¹¶å¡«å……ç‰‡æ®µä¸‹æ–¹çš„åŒºåŸŸï¼Œ
    å¤„ç†ç‰‡æ®µé—´æ–­ç‚¹ï¼Œå¹¶åœ¨ `Static` ç‰‡æ®µä¸Šè¦†ç›–äº¤å‰çº¿ï¼ŒåŒæ—¶æ ‡æ³¨ `orient` æ–¹å‘ã€‚

    å‚æ•°ï¼š
        orientation_segments (list[dict]): å§¿æ€ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - "start_frame": ç‰‡æ®µèµ·å§‹å¸§ç´¢å¼•ã€‚
            - "end_frame": ç‰‡æ®µç»“æŸå¸§ç´¢å¼•ã€‚
            - "head_y": å¤´éƒ¨é«˜åº¦ (å•å€¼æˆ– `[min, max]` åŒºé—´)ã€‚
            - "orient": å§¿åŠ¿æ–¹å‘ï¼ˆå¦‚ "neutral", "right", "up", "down"ï¼‰ã€‚

    è¿”å›ï¼š
        None: ç›´æ¥åœ¨ `matplotlib` ç”»å¸ƒä¸Šç»˜åˆ¶å›¾åƒï¼Œä¸è¿”å›å€¼ã€‚
    """

    if not orientation_segments:
        print("é”™è¯¯: orientation_segments ä¸ºç©ºï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚")
        return
    
    try:
        # è¯»å–å›¾ç‰‡
        # è¯»å–å›¾ç‰‡
        img_path = "full_body.png"
        img = Image.open(img_path)
        img_width, img_height = img.size
        aspect_ratio = img_width / img_height
        print(f"âœ… å›¾ç‰‡åŠ è½½æˆåŠŸ: {img_path} (å®½: {img_width}, é«˜: {img_height})")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¸»å›¾
    target_width_px = 1900  # å®½åº¦ 1920 åƒç´ 
    target_height_px = 700  # é«˜åº¦ 1080 åƒç´ 
    dpi = 100  # æ¯è‹±å¯¸çš„åƒç´ ç‚¹æ•°
    # è½¬æ¢ä¸ºè‹±å¯¸
    fig_width = target_width_px / dpi
    fig_height = target_height_px / dpi
    # åˆ›å»ºå›¾å½¢
    fig, ax = plt.subplots(figsize=(fig_width, fig_height))

    # **å®šä¹‰é¢œè‰²æ˜ å°„**
    color_map = {
        'neutral': '#8dd3c7',
        # 'right': '#ffffb3',
        'up': '#fb8072',
        'down': '#bebada',
        'down-neutral': '#fdb462',
        'neutral-down': '#fdb462',
        'up-neutral': '#b3de69',
        'neutral-up': '#b3de69',
        'down-up': '#fccde5',
        'up-down': '#fccde5'
    }

    # **éå† orientation_segmentsï¼Œç»˜åˆ¶ head_y è½¨è¿¹**
    for entry in orientation_segments:
        start_time = entry["start_frame"]
        end_time = entry["end_frame"]
        head_y = entry["head_y"]
        orient = entry["orient"]

        # **è·å–é¢œè‰²**
        color = color_map.get(orient, 'gray')

        # **ç”Ÿæˆ x è½´æ•°æ®**
        x_values = np.arange(start_time, end_time + 1)

        # **ç”Ÿæˆ y è½´æ•°æ®**
        if isinstance(head_y, (int, float)):  # **å•å€¼ï¼Œç»˜åˆ¶æ°´å¹³ç›´çº¿**
            y_values = np.full_like(x_values, head_y, dtype=float)

        elif isinstance(head_y, (list, tuple)) and len(head_y) == 2:  # **åŒºé—´å€¼ï¼Œç»˜åˆ¶æŒ¯è¡æ›²çº¿**
            min_val, max_val = head_y
            num_points = len(x_values)
            num_oscillations = 3  # æŒ‡å®šå¾€è¿”çš„æ¬¡æ•°

            # ä¸­é—´å€¼ (èµ·ç‚¹ä¸ç»ˆç‚¹)
            mid_val = (min_val + max_val) / 2

            # è®¡ç®—æ¯æ¬¡å¾€è¿”å ç”¨çš„ç‚¹æ•°ï¼ˆä¸¤ä¸ªæ¥å›ä¸ºä¸€ç»„ï¼‰
            points_per_oscillation = num_points // (num_oscillations * 4)
            
            indices = []
            for _ in range(num_oscillations):
                # ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¾€è¿”ï¼šä¸­é—´å€¼ -> max_val -> ä¸­é—´å€¼ -> min_val -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, max_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å¤§å€¼
                indices.extend(np.linspace(max_val, mid_val, points_per_oscillation))   # æœ€å¤§å€¼ -> ä¸­é—´å€¼
                indices.extend(np.linspace(mid_val, min_val, points_per_oscillation))   # ä¸­é—´å€¼ -> æœ€å°å€¼
                indices.extend(np.linspace(min_val, mid_val, points_per_oscillation))   # æœ€å°å€¼ -> ä¸­é—´å€¼

            # å¦‚æœç‚¹æ•°ä¸å¤Ÿï¼Œè¡¥ä¸Šä¸­é—´ç‚¹
            if len(indices) < num_points:
                indices = np.concatenate([indices, [mid_val] * (num_points - len(indices))])
            
            y_values = np.array(indices[:num_points])  # ç¡®ä¿ y_values çš„é•¿åº¦ä¸ x_values ä¸€è‡´
                
        else:
            continue  # **æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡**

        # **å¡«å……æ›²çº¿ä¸‹æ–¹çš„åŒºåŸŸ**
        plt.fill_between(x_values, y_values, 0, color=color, alpha=0.5, label=orient if orient not in plt.gca().get_legend_handles_labels()[1] else "")

        # **åœ¨ orientation ç‰‡æ®µé¡¶éƒ¨æ ‡æ³¨ orient**
        mid_x = (start_time + end_time) / 2
        mid_y = max(y_values) + 0.01  # **è®©æ–‡æœ¬ç¨å¾®é«˜äºæ›²çº¿**
        if '-' in orient:  # å¦‚æœæ˜¯è¿æ¥è¯
            word1, word2 = orient.split('-')
            # åˆ¤æ–­è¾ƒé•¿çš„å•è¯å’Œè¾ƒçŸ­çš„å•è¯
            if len(word1) >= len(word2):
                plt.text(mid_x, mid_y + 0.03, word1, fontsize=10 , ha='center', va='bottom', color='black', fontfamily='Arial')
                plt.text(mid_x, mid_y, f'&{word2}', fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
            else:
                plt.text(mid_x, mid_y + 0.03, word2, fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
                plt.text(mid_x, mid_y, f'&{word1}', fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')
        else:  # å¦‚æœæ˜¯å•è¯
            plt.text(mid_x, mid_y, orient, fontsize=10, ha='center', va='bottom', color='black', fontfamily='Arial')


    # **æ·»åŠ å›¾ä¾‹ã€æ ‡ç­¾ã€ç½‘æ ¼**
    plt.ylim(0, 1.1)
    plt.xlabel("Frame Index")
    plt.ylabel("Nose Height (Normalized)")
    plt.title("Nose Height and Facial Orientation Over Time")
    plt.legend(prop={'family': 'Arial'})
    plt.grid(True, linestyle='--', alpha=0.6)

    # åœ¨å·¦ä¾§æ·»åŠ å›¾ç‰‡
    target_height =  0.72
    target_width = target_height * aspect_ratio
    ax_img = fig.add_axes([0.03, 0.1, target_width, target_height], anchor='W')  # ç¡®ä¿å›¾ç‰‡çš„é«˜åº¦ä¸ 0-1 å¯¹é½
    ax_img.imshow(img)
    ax_img.axis('off')
    ax_img.set_zorder(0)

    # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„
    plt.savefig(save_path)
    plt.close(fig)












app = Flask(__name__)

UPLOAD_FOLDER = "static/uploads"
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

video_filename = None

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/overviews")
def overviews():
    return render_template("overviews.html")

@app.route("/upload")
def upload():
    return render_template("index.html")  # è¿™é‡Œå¯ä»¥ç”¨ index.html

@app.route("/analysis")
def analysis():
    return render_template("analysis.html")

@app.route("/upload", methods=["POST"])
def handle_upload():
    global video_filename
    if "video" not in request.files:
        return jsonify({"status": "error", "message": "No file uploaded."})

    file = request.files["video"]
    video_filename = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(video_filename)

    return jsonify({"status": "success"})

@app.route("/get_video")
def get_video():
    return jsonify({"video_url": "/" + video_filename if video_filename else None})

@app.route("/check_status")
def check_status():
    frame_data_list, fps= generate_video(video_filename)
    body_height, orientation, head_y = extract_data_from_frame_list(frame_data_list)
    orientation = smooth_stable_data(orientation)
    orientation_segments = first_orientation_segments(orientation, body_height, head_y, fps)
    orientation_segments, orientation, body_height, head_y = filter_invalid_orientation_segments(orientation_segments, orientation, body_height, head_y, fps)
    
    change_points = detect_change_points(body_height, visualize=False)
    orientation_segments, orientation, body_height, head_y = remove_large_height_changes(change_points, orientation_segments, orientation, body_height, head_y, fps)
    orientation_segments = merge_alternating_orients(orientation_segments, fps)
    orientation_segments, orientation, body_height, head_y = merge_orientation_segments(orientation_segments, orientation, body_height, head_y, fps)


    segmented_head_y = split_head_y_by_orientation(orientation_segments, head_y)
    segmented_head_y, split_info = process_segmented_head_y(segmented_head_y)
    print(split_info)

    periodics = []
    means = []
    amps = []
    for segment in segmented_head_y:
        segment = np.array(segment, dtype=float)
        periodic, mean, amp = detect_periodicity_acf_with_peaks(segment)
        if periodic:
            if amp < 0.05:
                periodic = False
        periodics.append(periodic)
        means.append(mean)
        amps.append(amp)
    
    orientation_segments = split_orientation_segments(orientation_segments, segmented_head_y, split_info)
    print(periodics)
    orientation_segments = update_orientation_segments(orientation_segments, periodics, means, amps)
    
    image_path = os.path.join(UPLOAD_FOLDER, 'result_plot.png')
    plot_orientation_segments(orientation_segments, image_path)


    segment1 = "This is a short sentence."
    segment2 = "This is a slightly longer sentence to test different lengths."
    segment3 = "This is a medium-length sentence designed to provide a more realistic placeholder."
    segment4 = "This is a very long sentence meant to serve as a placeholder for testing how longer text appears when inserted into the summary template, ensuring that the formatting remains intact and readable."
    segment5 = "Another short sentence to complete the set."

    summary_template = """Video analysis complete! The video contains several interesting segments:\n
    - 1. {Segment1}\n
    - 2. {Segment2}\n
    - 3. {Segment3}\n
    - 4. {Segment4}\n
    - 5. {Segment5}"""

    # ç”¨ format() æ–¹æ³•æ›¿æ¢å ä½ç¬¦
    analysis_result = {
        "summary": summary_template.format(
            Segment1=segment1,
            Segment2=segment2,
            Segment3=segment3,
            Segment4=segment4,
            Segment5=segment5
        ),
        "image_url": "/" + image_path if image_path else None
    }
    
    return jsonify({
            "done": True,
            "result": analysis_result["summary"],
            "image_url": analysis_result["image_url"]
        })

# if __name__ == "__main__":
#     app.run(debug=True)


